<p align="center">
    <a href="https://www.perplexity.ai/" title="Go to Perplexity">
        <img src="https://img.shields.io/badge/PERPLEXITY%20AI-20808d?style=for-the-badge&logo=data:image/png;base64,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" alt="Perplexity AI">
    </a>
</p>

<p align="center">
    <a href="https://github.com/RMNCLDYO/perplexity-ai-toolkit" title="Go to repo">
        <img src="https://img.shields.io/badge/dynamic/json?style=for-the-badge&label=Perplexity+AI+Toolkit&query=version&url=https%3A%2F%2Fraw.githubusercontent.com%2FRMNCLDYO%2Fperplexity-ai-toolkit%2Fmain%2F.github%2Fversion.json" alt="Perplexity AI Toolkit">
    </a>
</p>

<p align="center">
    <a href=".github/CHANGELOG.md" title="Go to changelog"><img src="https://img.shields.io/badge/maintained-yes-2ea44f?style=for-the-badge" alt="maintained - yes"></a>
    <a href=".github/CONTRIBUTING.md" title="Go to contributions"><img src="https://img.shields.io/badge/contributions-welcome-2ea44f?style=for-the-badge" alt="contributions - welcome"></a>
</p>

<p align="center">
    <a href="/">
        <picture>
          <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/RMNCLDYO/perplexity-ai-toolkit/main/.github/pplx-logo-dark.png">
          <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/RMNCLDYO/perplexity-ai-toolkit/main/.github/pplx-logo-light.png">
          <img alt="Perplexity AI" width="500" src="https://raw.githubusercontent.com/RMNCLDYO/perplexity-ai-toolkit/main/.github/pplx-logo-light.png">
        </picture>
    </a>
</p>

## Overview
The Perplexity AI Toolkit makes it easy to use Perplexity Labs' `Sonar` language models (built on top of Meta's latest and most advanced model `LLama-3.1`) for creating chatbots, generating text, and searching the web (***in real-time***). It's designed for everyone, from beginners to experienced developers, allowing quick addition of AI features to projects with simple commands. While it offers simplicity and lightweight integration, it doesn't compromise on power; experienced developers can access the full suite of advanced options available via the API, ensuring robust customization and control. This toolkit is perfect for those looking to efficiently tap into advanced AI without getting bogged down in technical details, yet it still provides the depth needed for complex project requirements.

## Key Features
- **Conversational AI**: Create interactive, real-time chat experiences (chatbots) or AI assistants.
- **Real-Time Web Search**: Conduct online searches in real-time with precise query responses.
- **Highly Customizable**: Tailor settings like streaming output, system prompts, sampling temperature and more to suit your specific requirements.
- **Lightweight Integration**: Efficiently designed with minimal dependencies, requiring only the `requests` package for core functionality.

## Prerequisites
- `Python 3.x`
- An API key from Perplexity AI

## Dependencies
The following Python packages are required:
- `requests`: For making HTTP requests to the Perplexity API.

The following Python packages are optional:
- `python-dotenv`: For managing API keys and other environment variables.

## Installation
To use the Perplexity AI Toolkit, clone the repository to your local machine and install the required Python packages.

Clone the repository:
```bash
git clone https://github.com/RMNCLDYO/perplexity-ai-toolkit.git
```

Navigate to the repositories folder:
```bash
cd perplexity-ai-toolkit
```

Install the required dependencies:
```bash
pip install -r requirements.txt
```

## Configuration
1. Obtain an API key from [Perplexity](https://www.perplexity.ai/).
2. You have three options for managing your API key:
   <details>
   <summary>Click here to view the API key configuration options</summary>
   
   - **Setting it as an environment variable on your device (recommended for everyday use)**
       - Navigate to your terminal.
       - Add your API key like so:
         ```shell
         export PERPLEXITY_API_KEY=your_api_key
         ```
       This method allows the API key to be loaded automatically when using the wrapper or CLI.
     
   - **Using an .env file (recommended for development):**
       - Install python-dotenv if you haven't already: `pip install python-dotenv`.
       - Create a .env file in the project's root directory.
       - Add your API key to the .env file like so:
         ```makefile
         PERPLEXITY_API_KEY=your_api_key
         ```
       This method allows the API key to be loaded automatically when using the wrapper or CLI, assuming you have python-dotenv installed and set up correctly.
     
   - **Direct Input:**
       - If you prefer not to use a `.env` file, you can directly pass your API key as an argument to the CLI or the wrapper functions.
         
         ***CLI***
         ```shell
         --api_key "your_api_key"
         ```
         ***Wrapper***
         ```shell
         api_key="your_api_key"
         ```
       This method requires manually inputting your API key each time you initiate an API call, ensuring flexibility for different deployment environments.
   </details>

## Usage
The Perplexity AI Toolkit can be used in two different modes: `Chat`, and `Search`. Each mode is designed for specific types of interactions with the language models.

## Chat Mode
Chat mode is intended for chatting with an AI model (similar to a chatbot) or building conversational applications.

#### Example Usage

***CLI***
```bash
python cli.py --chat
```

***Wrapper***
```python
from perplexity import Chat

Chat().run()
```

> An executable version of this example can be found [here](./examples/example_chat.py). (*You must move this file to the root folder before running the program.*)

## Search Mode
Search mode is intended for searching online (in real-time) for a single query as perplexity does not support multi-turn conversations with their online models.

#### Example Usage

***CLI***
```bash
python cli.py --search --query "What is today's date?"
```

***Wrapper***
```python
from perplexity import Search

Search().run(query="What is today's date?")
```

> An executable version of this example can be found [here](./examples/example_search.py). (*You must move this file to the root folder before running the program.*)

*Search mode is limited to 'online' models, such as `llama-3.1-sonar-small-128k-online`, `llama-3.1-sonar-large-128k-online` and `llama-3.1-sonar-huge-128k-online`.*

## Advanced Configuration

### CLI and Wrapper Options
| **Description**                          | **CLI Flags**                | **CLI Usage**                                       | **Wrapper Usage**                                 |
|------------------------------------------|------------------------------|-----------------------------------------------------|---------------------------------------------------|
| Enable chat mode                         | `-c`,  `--chat`              | --chat                                              | *See mode usage above*                            |
| Enable online search mode                | `-s`,  `--search`            | --search                                            | *See mode usage above*                            |
| Online search query                      | `-q`,  `--query`             | --query "What is today's date?"                     | query="What is today's date?"                     |
| User prompt                              | `-p`,  `--prompt`            | --prompt "How many stars are there in our galaxy?"  | prompt="How many stars are there in our galaxy?"  |
| API key for authentication               | `-a`,  `--api_key`           | --api_key your_api_key                              | api_key="your_api_key"                            |
| Model name                               | `-m`,  `--model`             | --model "llama-3.1-sonar-small-128k-chat"           | model="llama-3.1-sonar-small-128k-chat"           |
| Enable streaming mode                    | `-st`, `--stream`            | --stream                                            | stream=True                                       |
| System prompt (instructions)             | `-sp`, `--system_prompt`     | --system_prompt "Be precise and concise."           | system_prompt="Be precise and concise."           |
| Maximum tokens to generate               | `-mt`, `--max_tokens`        | --max_tokens 100                                    | max_tokens=100                                    |
| Sampling temperature                     | `-tm`, `--temperature`       | --temperature 0.7                                   | temperature=0.7                                   |
| Nucleus sampling threshold               | `-tp`, `--top_p`             | --top_p 0.9                                         | top_p=0.9                                         |
| Top-k sampling threshold                 | `-tk`, `--top_k`             | --top_k 40                                          | top_k=40                                          |
| Penalize tokens based on their presence  | `-pp`, `--presence_penalty`  | --presence_penalty 0.5                              | presence_penalty=0.5                              |
| Penalize tokens based on their frequency | `-fp`, `--frequency_penalty` | --frequency_penalty 0.5                             | frequency_penalty=0.5                             |

> *To exit the program at any time, you can type **`exit`** or **`quit`**. This command works similarly whether you're interacting with the program via the CLI or through the Python wrapper ensuring that you can easily and safely conclude your work with the Perplexity AI Toolkit without having to resort to interrupt signals or forcibly closing the terminal or command prompt.*

## Available Models

Perplexity offers both native models and a selection of large, open-source instruct models.

### Online Models

| **Model**                           | **Parameter Count** | **Context Length** |
|-------------------------------------|---------------------|--------------------|
| `llama-3.1-sonar-small-128k-online` | 8B                  | 127,072            |
| `llama-3.1-sonar-large-128k-online` | 70B                 | 127,072            |
| `llama-3.1-sonar-huge-128k-online`  | 405B                | 127,072            |

- *Perplexity makes note that the search subsystem of the Online LLMs do not attend to the system prompt. You can only use the system prompt to provide instructions related to style, tone, and language of the response.*

### Chat Models

| **Model**                         | **Parameter Count** | **Context Length** |
|-----------------------------------|---------------------|--------------------|
| `llama-3.1-sonar-small-128k-chat` | 8B                  | 131,072            |
| `llama-3.1-sonar-large-128k-chat` | 70B                 | 131,072            |

### Open-Source Models

| **Model**                | **Parameter Count** | **Context Length** |
|--------------------------|---------------------|--------------------|
| `llama-3.1-8b-instruct`  | 8B                  | 131,072            |
| `llama-3.1-70b-instruct` | 70B                 | 131,072            |

- *Where possible, Perplexity tries to match the Hugging Face implementation.*

## Contributing
Contributions are welcome!

Please refer to [CONTRIBUTING.md](.github/CONTRIBUTING.md) for detailed guidelines on how to contribute to this project.

## Reporting Issues
Encountered a bug? We'd love to hear about it. Please follow these steps to report any issues:

1. Check if the issue has already been reported.
2. Use the [Bug Report](.github/ISSUE_TEMPLATE/bug_report.md) template to create a detailed report.
3. Submit the report [here](https://github.com/RMNCLDYO/perplexity-ai-toolkit/issues).

Your report will help us make the project better for everyone.

## Feature Requests
Got an idea for a new feature? Feel free to suggest it. Here's how:

1. Check if the feature has already been suggested or implemented.
2. Use the [Feature Request](.github/ISSUE_TEMPLATE/feature_request.md) template to create a detailed request.
3. Submit the request [here](https://github.com/RMNCLDYO/perplexity-ai-toolkit/issues).

Your suggestions for improvements are always welcome.

## Versioning and Changelog
Stay up-to-date with the latest changes and improvements in each version:

- [CHANGELOG.md](.github/CHANGELOG.md) provides detailed descriptions of each release.

## Security
Your security is important to us. If you discover a security vulnerability, please follow our responsible disclosure guidelines found in [SECURITY.md](.github/SECURITY.md). Please refrain from disclosing any vulnerabilities publicly until said vulnerability has been reported and addressed.

## License
Licensed under the MIT License. See [LICENSE](LICENSE) for details.
